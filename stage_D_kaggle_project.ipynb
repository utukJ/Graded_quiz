{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stage_D_kaggle_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "12oROlU8FpBMy-t0GowzU-LvUR44AZ-Zj",
      "authorship_tag": "ABX9TyOFT8qky2vl6mgs2xHc13xg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/utukJ/Graded_quiz/blob/master/stage_D_kaggle_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH2C1Q8hMDdr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJIc3CtKMXsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip uninstall -y kaggle\n",
        "!pip install --upgrade pip\n",
        "!pip install kaggle==1.5.6\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp6zy-xeMxJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle datasets download -d nikitarom/planets-dataset\n",
        "!mkdir planets_dataset\n",
        "!unzip planets-dataset -d planets_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhUuK3VtPNsM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db7f3c0a-2638-4213-8ebb-d6d42261d46f"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_QNFbOy9Z8o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing relevant libraries\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
        "from tensorflow import keras\n",
        "from keras.layers import Conv2D, Dense, Flatten, MaxPooling2D, BatchNormalization, Dropout\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxtMK_yh-BlY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## obtaining csv files and setting up label mapping to integers\n",
        "\n",
        "train_classes = pd.read_csv(\"/content/planets_dataset/planet/planet/train_classes.csv\")\n",
        "sample_sub = pd.read_csv(\"/content/planets_dataset/planet/planet/sample_submission.csv\")\n",
        "\n",
        "label_map = {'agriculture': 14,\n",
        " 'artisinal_mine': 5,\n",
        " 'bare_ground': 1,\n",
        " 'blooming': 3,\n",
        " 'blow_down': 0,\n",
        " 'clear': 10,\n",
        " 'cloudy': 16,\n",
        " 'conventional_mine': 2,\n",
        " 'cultivation': 4,\n",
        " 'habitation': 9,\n",
        " 'haze': 6,\n",
        " 'partly_cloudy': 13,\n",
        " 'primary': 7,\n",
        " 'road': 11,\n",
        " 'selective_logging': 12,\n",
        " 'slash_burn': 8,\n",
        " 'water': 15}\n",
        "\n",
        "\n",
        "train_classes.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q29BYoPVKh97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating modified dataframe to implement \"flow_from_dataframe\" image processing\n",
        "\n",
        "train_dir = \"/content/planets_dataset/planet/planet/train-jpg/\"\n",
        "\n",
        "modified_df = train_classes.copy()\n",
        "modified_df[\"image_path\"] = train_dir + modified_df[\"image_name\"] + \".jpg\"\n",
        "\n",
        "# Add onehot features for every label\n",
        "for label in label_map.keys():\n",
        "    modified_df[label] = modified_df['tags'].apply(lambda x: 1 if label in x.split(' ') else 0)\n",
        "# Display head\n",
        "modified_df.head()\n",
        "\n",
        "\n",
        "# creating a data pipeline to feed training algorithm from dataframe\n",
        "\n",
        "img_size = 128\n",
        "\n",
        "data_gen = ImageDataGenerator(rescale = 1./255, \n",
        "                              validation_split = 0.2,\n",
        "                              rotation_range = 180,\n",
        "                              width_shift_range = 20,\n",
        "                              height_shift_range = 20,\n",
        "                              horizontal_flip = True,\n",
        "                              vertical_flip = True,\n",
        "                              fill_mode = \"reflect\")\n",
        "\n",
        "valid_data_gen = ImageDataGenerator(rescale = 1./255,\n",
        "                                    validation_split = 0.2)\n",
        "\n",
        "train_data_eff = data_gen.flow_from_dataframe(dataframe=modified_df,\n",
        "                                              x_col = \"image_path\",\n",
        "                                              y_col = label_map.keys(),\n",
        "                                              class_mode = \"raw\",\n",
        "                                              shuffle = True,\n",
        "                                              seed = 231,\n",
        "                                              target_size = (img_size, img_size),\n",
        "                                              subset = \"training\")\n",
        "\n",
        "valid_data_eff = valid_data_gen.flow_from_dataframe(dataframe=modified_df,\n",
        "                                              x_col = \"image_path\",\n",
        "                                              y_col = label_map.keys(),\n",
        "                                              class_mode = \"raw\",\n",
        "                                              shuffle = True,\n",
        "                                              seed = 231,\n",
        "                                              target_size = (img_size, img_size),\n",
        "                                              subset = \"validation\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ER_a328-qcO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# visualizing some images and their transformations after augmentation\n",
        "\n",
        "\n",
        "def to_tag(label_arr):\n",
        "  label_list = list(label_arr[0])\n",
        "  dict_keys = list(label_map.keys())\n",
        "  dict_vals = label_map.values()\n",
        "  tags = [dict_keys[i] for i in range(17) if label_list[i] == 1]\n",
        "  return \" \".join(tags)\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "\n",
        "  image, label = train_data_aug.next()\n",
        "  p_image, p_label = train_data.next()\n",
        "  print(\"label: \", to_tag(label))\n",
        "  image, p_image = image.reshape((64, 64, 3)), p_image.reshape((64, 64, 3))\n",
        "\n",
        "  fig = plt.figure(figsize = (10, 20))\n",
        "  ax = fig.add_subplot(5, 2, i*2 + 1)\n",
        "  ax.set_title(\"Augmented \")\n",
        "  plt.imshow(image)\n",
        "  ax = fig.add_subplot(5, 2, i*2 + 2)\n",
        "  ax.set_title(\"Not augmented \")\n",
        "  plt.imshow(p_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXB2nxQmHiv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function for fbeta evaluation metric\n",
        "\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "def fbeta(y_true, y_pred, threshold_shift=0):\n",
        "    beta = 2\n",
        "\n",
        "    # just in case of hipster activation at the final layer\n",
        "    y_pred = K.clip(y_pred, 0, 1)\n",
        "\n",
        "    # shifting the prediction threshold from .5 if needed\n",
        "    y_pred_bin = K.round(y_pred + threshold_shift)\n",
        "\n",
        "    tp = K.sum(K.round(y_true * y_pred_bin)) + K.epsilon()\n",
        "    fp = K.sum(K.round(K.clip(y_pred_bin - y_true, 0, 1)))\n",
        "    fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)))\n",
        "\n",
        "    precision = tp / (tp + fp)\n",
        "    recall = tp / (tp + fn)\n",
        "\n",
        "    beta_squared = beta ** 2\n",
        "    return (beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall + K.epsilon())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGNYBBzhp_9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def optimise_f2_thresholds(y, p, verbose=True, resolution=100):\n",
        "    #credits https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/discussion/32475\n",
        "  def mf(x):\n",
        "    p2 = np.zeros_like(p)\n",
        "    for i in range(17):\n",
        "      p2[:, i] = (p[:, i] > x[i]).astype(np.int)\n",
        "    score = fbeta_score(y, p2, beta=2, average='samples')\n",
        "    return score\n",
        "\n",
        "  x = [0.2]*17\n",
        "  for i in range(17):\n",
        "    best_i2 = 0\n",
        "    best_score = 0\n",
        "    for i2 in range(resolution):\n",
        "      i2 /= resolution\n",
        "      x[i] = i2\n",
        "      score = mf(x)\n",
        "      if score > best_score:\n",
        "        best_i2 = i2\n",
        "        best_score = score\n",
        "    x[i] = best_i2\n",
        "    if verbose:\n",
        "      print(i, best_i2, best_score)\n",
        "\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMvKQq9ciUHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## vgg based model\n",
        "\n",
        "from keras.applications import VGG19\n",
        "\n",
        "\n",
        "vgg_net = VGG19(include_top = False,\n",
        "                weights = 'imagenet',\n",
        "                input_shape = (img_size, img_size, 3))\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(vgg_net)\n",
        "model.add(Flatten())  \n",
        "model.add(Dense(1024, activation = \"relu\"))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(17, activation = \"sigmoid\"))\n",
        "\n",
        "model_name = \"nnet_vggnet\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfEMhKcOZqxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## xception based model\n",
        "\n",
        "from keras.applications import Xception\n",
        "\n",
        "\n",
        "xception_model = Xception(include_top=False,\n",
        "                          weights=\"imagenet\",\n",
        "                          input_shape=(img_size, img_size, 3))\n",
        "\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(xception_model)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, \"relu\"))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(17, activation = \"sigmoid\"))\n",
        "\n",
        "model_name = \"nnet_xception\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OiYuFnEFZDV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e25a7a53-a313-444c-b151-b865e84611a6"
      },
      "source": [
        "# Resnet50 based model \n",
        "\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "\n",
        "res_net_model = ResNet50(input_shape = (img_size, img_size, 3),\n",
        "                   include_top = False,\n",
        "                   weights = \"imagenet\")\n",
        "\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(res_net_model)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation = \"relu\"))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(17, activation = \"sigmoid\"))\n",
        "\n",
        "model_name = \"nnet_resnet50\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ1AmDi1ixsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## compiling model and training\n",
        "\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_fbeta',\n",
        "                           mode = \"max\",\n",
        "                            patience=5,\n",
        "                            verbose=1,\n",
        "                            min_delta=1e-4),\n",
        "              ReduceLROnPlateau(monitor='val_fbeta',\n",
        "                                factor=0.1,\n",
        "                                patience=2,\n",
        "                                cooldown=2,\n",
        "                                mode = \"max\",\n",
        "                                verbose=1),\n",
        "             ModelCheckpoint(filepath = \"/content/gdrive/My Drive/weights/{}_huge.hdf5\".format(model_name),\n",
        "                             monitor='val_fbeta',\n",
        "                             mode = \"max\",\n",
        "                             save_weights_only = True,\n",
        "                             save_best_only = True,\n",
        "                             verbose = 1)]\n",
        "\n",
        "\n",
        "\n",
        "model.compile(loss = \"binary_crossentropy\", optimizer = Adam(1e-4), metrics = [fbeta])\n",
        "model.fit(train_data_eff, validation_data = valid_data_eff, epochs = 50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-y7ro8LlGrW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ff65dd30-43c1-4da2-8416-777032ee1a22"
      },
      "source": [
        " ## evaluating trained model\n",
        "\n",
        "model.evaluate(valid_data_eff)\n",
        "model.evaluate(train_data_eff)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "253/253 [==============================] - 30s 117ms/step - loss: 0.0917 - fbeta: 0.8909\n",
            "1012/1012 [==============================] - 234s 231ms/step - loss: 0.0726 - fbeta: 0.9013\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07261151820421219, 0.9013378024101257]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucgjUCchxzHe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5f1fa640-dc63-4d2c-c46d-4f025264c99a"
      },
      "source": [
        "\n",
        "y_val = np.zeros((1, 17))\n",
        "\n",
        "for i in range(253):\n",
        "  _, label = valid_data_eff.next()\n",
        "  y_val = np.vstack((y_val, label))\n",
        "\n",
        "\n",
        "y_val = y_val[1:, :]\n",
        "\n",
        "p_val = model.predict(valid_data_eff)\n",
        "\n",
        "print(\"p val shape: \", p_val.shape)\n",
        "print(\"y val shape: \", y_val.shape)\n",
        "\n",
        "# print(\"Evaluation after test time augmentation: \", fbeta_score(y_val, p_val, beta = 2, mode = ))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p val shape:  (8095, 17)\n",
            "y val shape:  (8095, 17)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuBCHNM1HFuW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "16de0ca8-3ce5-43c7-ed79-393e4a930007"
      },
      "source": [
        "thresholds = optimise_f2_thresholds(y_val, p_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.21 0.9194155385903352\n",
            "1 0.1 0.9194926079993877\n",
            "2 0.14 0.919612357917968\n",
            "3 0.23 0.9196126921523974\n",
            "4 0.06 0.9196889455357464\n",
            "5 0.3 0.9199276463850321\n",
            "6 0.02 0.9225129460045101\n",
            "7 0.24 0.9225169830321274\n",
            "8 0.26 0.9226441984780803\n",
            "9 0.18 0.9227042721893643\n",
            "10 0.14 0.9234138060283977\n",
            "11 0.15 0.9235607866411317\n",
            "12 0.44 0.9242074009261954\n",
            "13 0.33 0.9245146599404346\n",
            "14 0.2 0.9245146599404346\n",
            "15 0.16 0.9245454511284396\n",
            "16 0.15 0.9247787857396048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hst99gPLz-bo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "df365352-223f-42b0-ca8f-8cdae6165c6d"
      },
      "source": [
        "# creating modified dataframe to implement \"flow_from_dataframe\" image processing\n",
        "\n",
        "test_dir = \"/content/planets_dataset/planet/planet/test-jpg/\"\n",
        "additional_dir = \"/content/planets_dataset/test-jpg-additional/test-jpg-additional/\"\n",
        "\n",
        "num_test = len(os.listdir(test_dir))\n",
        "\n",
        "test_df = sample_sub.copy().iloc[:num_test]\n",
        "add_df = sample_sub.copy().iloc[num_test:]\n",
        "test_df[\"image_dir\"] = test_dir + test_df.image_name + \".jpg\"\n",
        "add_df[\"image_dir\"] = additional_dir + add_df.image_name + \".jpg\"\n",
        "\n",
        "modified_test_df = pd.concat((test_df, add_df))\n",
        "modified_test_df\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>tags</th>\n",
              "      <th>image_dir</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_0</td>\n",
              "      <td>primary clear agriculture road water</td>\n",
              "      <td>/content/planets_dataset/planet/planet/test-jp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_1</td>\n",
              "      <td>primary clear agriculture road water</td>\n",
              "      <td>/content/planets_dataset/planet/planet/test-jp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_2</td>\n",
              "      <td>primary clear agriculture road water</td>\n",
              "      <td>/content/planets_dataset/planet/planet/test-jp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test_3</td>\n",
              "      <td>primary clear agriculture road water</td>\n",
              "      <td>/content/planets_dataset/planet/planet/test-jp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test_4</td>\n",
              "      <td>primary clear agriculture road water</td>\n",
              "      <td>/content/planets_dataset/planet/planet/test-jp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61186</th>\n",
              "      <td>file_9995</td>\n",
              "      <td>primary clear agriculture road water</td>\n",
              "      <td>/content/planets_dataset/test-jpg-additional/t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61187</th>\n",
              "      <td>file_9996</td>\n",
              "      <td>primary clear agriculture road water</td>\n",
              "      <td>/content/planets_dataset/test-jpg-additional/t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61188</th>\n",
              "      <td>file_9997</td>\n",
              "      <td>primary clear agriculture road water</td>\n",
              "      <td>/content/planets_dataset/test-jpg-additional/t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61189</th>\n",
              "      <td>file_9998</td>\n",
              "      <td>primary clear agriculture road water</td>\n",
              "      <td>/content/planets_dataset/test-jpg-additional/t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61190</th>\n",
              "      <td>file_9999</td>\n",
              "      <td>primary clear agriculture road water</td>\n",
              "      <td>/content/planets_dataset/test-jpg-additional/t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>61191 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      image_name  ...                                          image_dir\n",
              "0         test_0  ...  /content/planets_dataset/planet/planet/test-jp...\n",
              "1         test_1  ...  /content/planets_dataset/planet/planet/test-jp...\n",
              "2         test_2  ...  /content/planets_dataset/planet/planet/test-jp...\n",
              "3         test_3  ...  /content/planets_dataset/planet/planet/test-jp...\n",
              "4         test_4  ...  /content/planets_dataset/planet/planet/test-jp...\n",
              "...          ...  ...                                                ...\n",
              "61186  file_9995  ...  /content/planets_dataset/test-jpg-additional/t...\n",
              "61187  file_9996  ...  /content/planets_dataset/test-jpg-additional/t...\n",
              "61188  file_9997  ...  /content/planets_dataset/test-jpg-additional/t...\n",
              "61189  file_9998  ...  /content/planets_dataset/test-jpg-additional/t...\n",
              "61190  file_9999  ...  /content/planets_dataset/test-jpg-additional/t...\n",
              "\n",
              "[61191 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjOUSEUizOxV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2910a0e3-23f4-4760-b2c1-9cb3b5ceae19"
      },
      "source": [
        "# creating a data pipeline for the test data\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "test_data = test_datagen.flow_from_dataframe(modified_test_df, x_col = \"image_dir\", batch_size = 32, shuffle = False, target_size = (img_size, img_size), class_mode = None)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 61191 validated image filenames.\n",
            "Found 61191 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfKKA1_41uTf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "05870a29-8704-47ae-a8d3-68b7f198d093"
      },
      "source": [
        "# making predictions on test data\n",
        "\n",
        "predictions = np.array(model.predict(test_data, verbose = 1) > thresholds , dtype = int)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   2/1913 [..............................] - ETA: 1:14WARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0299s vs `on_predict_batch_end` time: 0.0515s). Check your callbacks.\n",
            "1913/1913 [==============================] - 149s 78ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxSXAhyX-zsE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "352e62e1-5f0a-4356-d905-270245c0c6eb"
      },
      "source": [
        " # converting output to label tags for submission.csv file\n",
        "\n",
        "mySubmission = sample_sub.copy()\n",
        "sorted_labels = list(label_map.keys())\n",
        "\n",
        "for i in tqdm(range(predictions.shape[0])):\n",
        "  tag = \"\"\n",
        "  x = predictions[i]\n",
        "  for lbl in sorted_labels:\n",
        "    if x[sorted_labels.index(lbl)] == 1:\n",
        "      tag += \" \" + lbl\n",
        "  mySubmission[\"tags\"][i] = tag[1:]\n",
        "\n",
        "\n",
        "# saving the submission to a csv file\n",
        "\n",
        "mySubmission.to_csv(\"submission.csv\", index = False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/61191 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 357/61191 [00:00<00:17, 3561.99it/s]\u001b[A\n",
            "  1%|          | 685/61191 [00:00<00:17, 3470.07it/s]\u001b[A\n",
            "  2%|▏         | 989/61191 [00:00<00:18, 3328.17it/s]\u001b[A\n",
            "  2%|▏         | 1347/61191 [00:00<00:17, 3399.65it/s]\u001b[A\n",
            "  3%|▎         | 1670/61191 [00:00<00:17, 3346.72it/s]\u001b[A\n",
            "  3%|▎         | 1988/61191 [00:00<00:17, 3293.93it/s]\u001b[A\n",
            "  4%|▍         | 2342/61191 [00:00<00:17, 3362.98it/s]\u001b[A\n",
            "  4%|▍         | 2660/61191 [00:00<00:17, 3302.37it/s]\u001b[A\n",
            "  5%|▍         | 3005/61191 [00:00<00:17, 3343.60it/s]\u001b[A\n",
            "  5%|▌         | 3326/61191 [00:01<00:18, 3181.89it/s]\u001b[A\n",
            "  6%|▌         | 3637/61191 [00:01<00:18, 3129.89it/s]\u001b[A\n",
            "  6%|▋         | 3969/61191 [00:01<00:17, 3182.48it/s]\u001b[A\n",
            "  7%|▋         | 4284/61191 [00:01<00:18, 3080.97it/s]\u001b[A\n",
            "  8%|▊         | 4591/61191 [00:01<00:18, 3072.57it/s]\u001b[A\n",
            "  8%|▊         | 4934/61191 [00:01<00:17, 3170.48it/s]\u001b[A\n",
            "  9%|▊         | 5279/61191 [00:01<00:17, 3247.28it/s]\u001b[A\n",
            "  9%|▉         | 5605/61191 [00:01<00:17, 3190.49it/s]\u001b[A\n",
            " 10%|▉         | 5929/61191 [00:01<00:17, 3203.72it/s]\u001b[A\n",
            " 10%|█         | 6272/61191 [00:01<00:16, 3268.40it/s]\u001b[A\n",
            " 11%|█         | 6600/61191 [00:02<00:17, 3189.90it/s]\u001b[A\n",
            " 11%|█▏        | 6939/61191 [00:02<00:16, 3244.83it/s]\u001b[A\n",
            " 12%|█▏        | 7265/61191 [00:02<00:17, 3171.61it/s]\u001b[A\n",
            " 12%|█▏        | 7584/61191 [00:02<00:16, 3155.16it/s]\u001b[A\n",
            " 13%|█▎        | 7901/61191 [00:02<00:17, 3101.72it/s]\u001b[A\n",
            " 13%|█▎        | 8212/61191 [00:02<00:17, 3012.04it/s]\u001b[A\n",
            " 14%|█▍        | 8515/61191 [00:02<00:17, 3012.74it/s]\u001b[A\n",
            " 14%|█▍        | 8818/61191 [00:02<00:17, 3000.87it/s]\u001b[A\n",
            " 15%|█▍        | 9119/61191 [00:02<00:17, 2962.55it/s]\u001b[A\n",
            " 15%|█▌        | 9428/61191 [00:02<00:17, 2997.33it/s]\u001b[A\n",
            " 16%|█▌        | 9742/61191 [00:03<00:16, 3038.28it/s]\u001b[A\n",
            " 16%|█▋        | 10089/61191 [00:03<00:16, 3154.73it/s]\u001b[A\n",
            " 17%|█▋        | 10432/61191 [00:03<00:15, 3230.76it/s]\u001b[A\n",
            " 18%|█▊        | 10768/61191 [00:03<00:15, 3267.75it/s]\u001b[A\n",
            " 18%|█▊        | 11108/61191 [00:03<00:15, 3305.38it/s]\u001b[A\n",
            " 19%|█▊        | 11452/61191 [00:03<00:14, 3342.71it/s]\u001b[A\n",
            " 19%|█▉        | 11797/61191 [00:03<00:14, 3372.93it/s]\u001b[A\n",
            " 20%|█▉        | 12149/61191 [00:03<00:14, 3413.47it/s]\u001b[A\n",
            " 20%|██        | 12491/61191 [00:03<00:14, 3367.04it/s]\u001b[A\n",
            " 21%|██        | 12829/61191 [00:03<00:14, 3316.78it/s]\u001b[A\n",
            " 22%|██▏       | 13168/61191 [00:04<00:14, 3336.05it/s]\u001b[A\n",
            " 22%|██▏       | 13511/61191 [00:04<00:14, 3361.23it/s]\u001b[A\n",
            " 23%|██▎       | 13862/61191 [00:04<00:13, 3404.10it/s]\u001b[A\n",
            " 23%|██▎       | 14203/61191 [00:04<00:13, 3366.10it/s]\u001b[A\n",
            " 24%|██▍       | 14552/61191 [00:04<00:13, 3400.44it/s]\u001b[A\n",
            " 24%|██▍       | 14893/61191 [00:04<00:13, 3395.30it/s]\u001b[A\n",
            " 25%|██▍       | 15233/61191 [00:04<00:13, 3396.61it/s]\u001b[A\n",
            " 25%|██▌       | 15573/61191 [00:04<00:13, 3345.31it/s]\u001b[A\n",
            " 26%|██▌       | 15913/61191 [00:04<00:13, 3359.04it/s]\u001b[A\n",
            " 27%|██▋       | 16260/61191 [00:05<00:13, 3389.47it/s]\u001b[A\n",
            " 27%|██▋       | 16600/61191 [00:05<00:13, 3366.67it/s]\u001b[A\n",
            " 28%|██▊       | 16949/61191 [00:05<00:13, 3401.88it/s]\u001b[A\n",
            " 28%|██▊       | 17290/61191 [00:05<00:12, 3398.29it/s]\u001b[A\n",
            " 29%|██▉       | 17630/61191 [00:05<00:13, 3345.15it/s]\u001b[A\n",
            " 29%|██▉       | 17978/61191 [00:05<00:12, 3382.32it/s]\u001b[A\n",
            " 30%|██▉       | 18317/61191 [00:05<00:12, 3366.03it/s]\u001b[A\n",
            " 30%|███       | 18654/61191 [00:05<00:12, 3355.64it/s]\u001b[A\n",
            " 31%|███       | 18990/61191 [00:05<00:12, 3345.52it/s]\u001b[A\n",
            " 32%|███▏      | 19325/61191 [00:05<00:12, 3335.51it/s]\u001b[A\n",
            " 32%|███▏      | 19668/61191 [00:06<00:12, 3362.98it/s]\u001b[A\n",
            " 33%|███▎      | 20005/61191 [00:06<00:12, 3291.61it/s]\u001b[A\n",
            " 33%|███▎      | 20335/61191 [00:06<00:12, 3245.70it/s]\u001b[A\n",
            " 34%|███▍      | 20661/61191 [00:06<00:12, 3238.93it/s]\u001b[A\n",
            " 34%|███▍      | 20991/61191 [00:06<00:12, 3254.94it/s]\u001b[A\n",
            " 35%|███▍      | 21335/61191 [00:06<00:12, 3306.03it/s]\u001b[A\n",
            " 35%|███▌      | 21677/61191 [00:06<00:11, 3337.47it/s]\u001b[A\n",
            " 36%|███▌      | 22020/61191 [00:06<00:11, 3364.15it/s]\u001b[A\n",
            " 37%|███▋      | 22357/61191 [00:06<00:11, 3351.52it/s]\u001b[A\n",
            " 37%|███▋      | 22693/61191 [00:06<00:11, 3331.34it/s]\u001b[A\n",
            " 38%|███▊      | 23034/61191 [00:07<00:11, 3352.33it/s]\u001b[A\n",
            " 38%|███▊      | 23370/61191 [00:07<00:11, 3305.52it/s]\u001b[A\n",
            " 39%|███▊      | 23706/61191 [00:07<00:11, 3320.44it/s]\u001b[A\n",
            " 39%|███▉      | 24049/61191 [00:07<00:11, 3351.51it/s]\u001b[A\n",
            " 40%|███▉      | 24385/61191 [00:07<00:11, 3333.41it/s]\u001b[A\n",
            " 40%|████      | 24720/61191 [00:07<00:10, 3338.21it/s]\u001b[A\n",
            " 41%|████      | 25062/61191 [00:07<00:10, 3360.72it/s]\u001b[A\n",
            " 42%|████▏     | 25399/61191 [00:07<00:10, 3362.45it/s]\u001b[A\n",
            " 42%|████▏     | 25736/61191 [00:07<00:10, 3320.64it/s]\u001b[A\n",
            " 43%|████▎     | 26077/61191 [00:07<00:10, 3344.71it/s]\u001b[A\n",
            " 43%|████▎     | 26423/61191 [00:08<00:10, 3376.75it/s]\u001b[A\n",
            " 44%|████▎     | 26761/61191 [00:08<00:10, 3338.98it/s]\u001b[A\n",
            " 44%|████▍     | 27096/61191 [00:08<00:10, 3256.25it/s]\u001b[A\n",
            " 45%|████▍     | 27437/61191 [00:08<00:10, 3299.11it/s]\u001b[A\n",
            " 45%|████▌     | 27768/61191 [00:08<00:10, 3197.70it/s]\u001b[A\n",
            " 46%|████▌     | 28089/61191 [00:08<00:10, 3148.82it/s]\u001b[A\n",
            " 46%|████▋     | 28427/61191 [00:08<00:10, 3212.73it/s]\u001b[A\n",
            " 47%|████▋     | 28750/61191 [00:08<00:10, 3170.85it/s]\u001b[A\n",
            " 48%|████▊     | 29084/61191 [00:08<00:09, 3219.45it/s]\u001b[A\n",
            " 48%|████▊     | 29428/61191 [00:08<00:09, 3280.79it/s]\u001b[A\n",
            " 49%|████▊     | 29763/61191 [00:09<00:09, 3301.01it/s]\u001b[A\n",
            " 49%|████▉     | 30103/61191 [00:09<00:09, 3327.93it/s]\u001b[A\n",
            " 50%|████▉     | 30444/61191 [00:09<00:09, 3351.36it/s]\u001b[A\n",
            " 50%|█████     | 30780/61191 [00:09<00:09, 3283.61it/s]\u001b[A\n",
            " 51%|█████     | 31109/61191 [00:09<00:09, 3239.17it/s]\u001b[A\n",
            " 51%|█████▏    | 31434/61191 [00:09<00:09, 3208.02it/s]\u001b[A\n",
            " 52%|█████▏    | 31756/61191 [00:09<00:09, 3156.99it/s]\u001b[A\n",
            " 52%|█████▏    | 32086/61191 [00:09<00:09, 3197.03it/s]\u001b[A\n",
            " 53%|█████▎    | 32421/61191 [00:09<00:08, 3240.73it/s]\u001b[A\n",
            " 54%|█████▎    | 32757/61191 [00:10<00:08, 3273.62it/s]\u001b[A\n",
            " 54%|█████▍    | 33085/61191 [00:10<00:08, 3251.26it/s]\u001b[A\n",
            " 55%|█████▍    | 33418/61191 [00:10<00:08, 3273.08it/s]\u001b[A\n",
            " 55%|█████▌    | 33754/61191 [00:10<00:08, 3296.23it/s]\u001b[A\n",
            " 56%|█████▌    | 34084/61191 [00:10<00:08, 3264.79it/s]\u001b[A\n",
            " 56%|█████▌    | 34411/61191 [00:10<00:08, 3226.32it/s]\u001b[A\n",
            " 57%|█████▋    | 34734/61191 [00:10<00:08, 3224.06it/s]\u001b[A\n",
            " 57%|█████▋    | 35068/61191 [00:10<00:08, 3256.90it/s]\u001b[A\n",
            " 58%|█████▊    | 35404/61191 [00:10<00:07, 3284.80it/s]\u001b[A\n",
            " 58%|█████▊    | 35737/61191 [00:10<00:07, 3295.92it/s]\u001b[A\n",
            " 59%|█████▉    | 36067/61191 [00:11<00:07, 3256.67it/s]\u001b[A\n",
            " 59%|█████▉    | 36396/61191 [00:11<00:07, 3266.23it/s]\u001b[A\n",
            " 60%|██████    | 36724/61191 [00:11<00:07, 3267.78it/s]\u001b[A\n",
            " 61%|██████    | 37060/61191 [00:11<00:07, 3294.58it/s]\u001b[A\n",
            " 61%|██████    | 37395/61191 [00:11<00:07, 3308.72it/s]\u001b[A\n",
            " 62%|██████▏   | 37726/61191 [00:11<00:07, 3261.65it/s]\u001b[A\n",
            " 62%|██████▏   | 38053/61191 [00:11<00:07, 3253.76it/s]\u001b[A\n",
            " 63%|██████▎   | 38379/61191 [00:11<00:07, 3158.19it/s]\u001b[A\n",
            " 63%|██████▎   | 38696/61191 [00:11<00:07, 3123.80it/s]\u001b[A\n",
            " 64%|██████▎   | 39009/61191 [00:11<00:07, 3104.42it/s]\u001b[A\n",
            " 64%|██████▍   | 39340/61191 [00:12<00:06, 3161.32it/s]\u001b[A\n",
            " 65%|██████▍   | 39657/61191 [00:12<00:06, 3135.54it/s]\u001b[A\n",
            " 65%|██████▌   | 39971/61191 [00:12<00:06, 3074.90it/s]\u001b[A\n",
            " 66%|██████▌   | 40280/61191 [00:12<00:06, 3074.75it/s]\u001b[A\n",
            " 66%|██████▋   | 40589/61191 [00:12<00:06, 3076.08it/s]\u001b[A\n",
            " 67%|██████▋   | 40897/61191 [00:12<00:06, 3013.05it/s]\u001b[A\n",
            " 67%|██████▋   | 41214/61191 [00:12<00:06, 3057.56it/s]\u001b[A\n",
            " 68%|██████▊   | 41524/61191 [00:12<00:06, 3069.58it/s]\u001b[A\n",
            " 68%|██████▊   | 41835/61191 [00:12<00:06, 3081.07it/s]\u001b[A\n",
            " 69%|██████▉   | 42149/61191 [00:12<00:06, 3097.52it/s]\u001b[A\n",
            " 69%|██████▉   | 42459/61191 [00:13<00:06, 3085.48it/s]\u001b[A\n",
            " 70%|██████▉   | 42768/61191 [00:13<00:06, 3027.64it/s]\u001b[A\n",
            " 70%|███████   | 43085/61191 [00:13<00:05, 3068.90it/s]\u001b[A\n",
            " 71%|███████   | 43402/61191 [00:13<00:05, 3096.71it/s]\u001b[A\n",
            " 71%|███████▏  | 43712/61191 [00:13<00:05, 3097.56it/s]\u001b[A\n",
            " 72%|███████▏  | 44022/61191 [00:13<00:05, 3086.08it/s]\u001b[A\n",
            " 72%|███████▏  | 44331/61191 [00:13<00:05, 2986.43it/s]\u001b[A\n",
            " 73%|███████▎  | 44631/61191 [00:13<00:05, 2934.80it/s]\u001b[A\n",
            " 73%|███████▎  | 44926/61191 [00:13<00:05, 2909.56it/s]\u001b[A\n",
            " 74%|███████▍  | 45231/61191 [00:13<00:05, 2949.59it/s]\u001b[A\n",
            " 74%|███████▍  | 45527/61191 [00:14<00:05, 2919.03it/s]\u001b[A\n",
            " 75%|███████▍  | 45820/61191 [00:14<00:05, 2919.38it/s]\u001b[A\n",
            " 75%|███████▌  | 46113/61191 [00:14<00:05, 2900.72it/s]\u001b[A\n",
            " 76%|███████▌  | 46443/61191 [00:14<00:04, 3007.90it/s]\u001b[A\n",
            " 76%|███████▋  | 46745/61191 [00:14<00:04, 2984.81it/s]\u001b[A\n",
            " 77%|███████▋  | 47045/61191 [00:14<00:04, 2901.93it/s]\u001b[A\n",
            " 77%|███████▋  | 47352/61191 [00:14<00:04, 2947.93it/s]\u001b[A\n",
            " 78%|███████▊  | 47648/61191 [00:14<00:04, 2951.36it/s]\u001b[A\n",
            " 78%|███████▊  | 47970/61191 [00:14<00:04, 3026.58it/s]\u001b[A\n",
            " 79%|███████▉  | 48298/61191 [00:15<00:04, 3096.00it/s]\u001b[A\n",
            " 79%|███████▉  | 48625/61191 [00:15<00:03, 3144.12it/s]\u001b[A\n",
            " 80%|███████▉  | 48941/61191 [00:15<00:03, 3146.68it/s]\u001b[A\n",
            " 81%|████████  | 49272/61191 [00:15<00:03, 3193.54it/s]\u001b[A\n",
            " 81%|████████  | 49592/61191 [00:15<00:03, 3176.33it/s]\u001b[A\n",
            " 82%|████████▏ | 49921/61191 [00:15<00:03, 3207.75it/s]\u001b[A\n",
            " 82%|████████▏ | 50243/61191 [00:15<00:03, 3168.18it/s]\u001b[A\n",
            " 83%|████████▎ | 50561/61191 [00:15<00:03, 3149.86it/s]\u001b[A\n",
            " 83%|████████▎ | 50877/61191 [00:15<00:03, 3148.34it/s]\u001b[A\n",
            " 84%|████████▎ | 51202/61191 [00:15<00:03, 3176.54it/s]\u001b[A\n",
            " 84%|████████▍ | 51531/61191 [00:16<00:03, 3207.47it/s]\u001b[A\n",
            " 85%|████████▍ | 51852/61191 [00:16<00:02, 3153.24it/s]\u001b[A\n",
            " 85%|████████▌ | 52168/61191 [00:16<00:02, 3146.16it/s]\u001b[A\n",
            " 86%|████████▌ | 52496/61191 [00:16<00:02, 3182.67it/s]\u001b[A\n",
            " 86%|████████▋ | 52819/61191 [00:16<00:02, 3194.78it/s]\u001b[A\n",
            " 87%|████████▋ | 53139/61191 [00:16<00:02, 3134.10it/s]\u001b[A\n",
            " 87%|████████▋ | 53453/61191 [00:16<00:02, 3131.57it/s]\u001b[A\n",
            " 88%|████████▊ | 53767/61191 [00:16<00:02, 3107.83it/s]\u001b[A\n",
            " 88%|████████▊ | 54079/61191 [00:16<00:02, 3093.60it/s]\u001b[A\n",
            " 89%|████████▉ | 54401/61191 [00:16<00:02, 3128.49it/s]\u001b[A\n",
            " 89%|████████▉ | 54725/61191 [00:17<00:02, 3160.71it/s]\u001b[A\n",
            " 90%|████████▉ | 55047/61191 [00:17<00:01, 3177.25it/s]\u001b[A\n",
            " 90%|█████████ | 55365/61191 [00:17<00:01, 3134.66it/s]\u001b[A\n",
            " 91%|█████████ | 55687/61191 [00:17<00:01, 3158.03it/s]\u001b[A\n",
            " 92%|█████████▏| 56004/61191 [00:17<00:01, 3137.50it/s]\u001b[A\n",
            " 92%|█████████▏| 56318/61191 [00:17<00:01, 3126.81it/s]\u001b[A\n",
            " 93%|█████████▎| 56631/61191 [00:17<00:01, 3094.23it/s]\u001b[A\n",
            " 93%|█████████▎| 56941/61191 [00:17<00:01, 3064.15it/s]\u001b[A\n",
            " 94%|█████████▎| 57248/61191 [00:17<00:01, 3019.87it/s]\u001b[A\n",
            " 94%|█████████▍| 57551/61191 [00:17<00:01, 3006.13it/s]\u001b[A\n",
            " 95%|█████████▍| 57852/61191 [00:18<00:01, 2933.26it/s]\u001b[A\n",
            " 95%|█████████▌| 58146/61191 [00:18<00:01, 2911.92it/s]\u001b[A\n",
            " 96%|█████████▌| 58438/61191 [00:18<00:00, 2886.00it/s]\u001b[A\n",
            " 96%|█████████▌| 58744/61191 [00:18<00:00, 2935.95it/s]\u001b[A\n",
            " 96%|█████████▋| 59046/61191 [00:18<00:00, 2960.04it/s]\u001b[A\n",
            " 97%|█████████▋| 59343/61191 [00:18<00:00, 2960.67it/s]\u001b[A\n",
            " 97%|█████████▋| 59658/61191 [00:18<00:00, 3013.77it/s]\u001b[A\n",
            " 98%|█████████▊| 59960/61191 [00:18<00:00, 3002.14it/s]\u001b[A\n",
            " 99%|█████████▊| 60278/61191 [00:18<00:00, 3051.89it/s]\u001b[A\n",
            " 99%|█████████▉| 60600/61191 [00:18<00:00, 3098.62it/s]\u001b[A\n",
            "100%|██████████| 61191/61191 [00:19<00:00, 3192.92it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVvXOpAmC3n4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "4dca7178-0c60-4147-f861-78f692aa8df0"
      },
      "source": [
        "mySubmission"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_0</td>\n",
              "      <td>clear primary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_1</td>\n",
              "      <td>clear primary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_2</td>\n",
              "      <td>partly_cloudy primary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test_3</td>\n",
              "      <td>agriculture clear cultivation primary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test_4</td>\n",
              "      <td>cloudy partly_cloudy primary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61186</th>\n",
              "      <td>file_9995</td>\n",
              "      <td>cloudy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61187</th>\n",
              "      <td>file_9996</td>\n",
              "      <td>clear primary water</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61188</th>\n",
              "      <td>file_9997</td>\n",
              "      <td>clear primary road water</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61189</th>\n",
              "      <td>file_9998</td>\n",
              "      <td>cloudy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61190</th>\n",
              "      <td>file_9999</td>\n",
              "      <td>clear habitation primary road</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>61191 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      image_name                                   tags\n",
              "0         test_0                          clear primary\n",
              "1         test_1                          clear primary\n",
              "2         test_2                  partly_cloudy primary\n",
              "3         test_3  agriculture clear cultivation primary\n",
              "4         test_4           cloudy partly_cloudy primary\n",
              "...          ...                                    ...\n",
              "61186  file_9995                                 cloudy\n",
              "61187  file_9996                    clear primary water\n",
              "61188  file_9997               clear primary road water\n",
              "61189  file_9998                                 cloudy\n",
              "61190  file_9999          clear habitation primary road\n",
              "\n",
              "[61191 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ibRfw6HMQSW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fd48eaf0-868a-491d-d4f2-17a02526fb5c"
      },
      "source": [
        "# making submission on kaggle\n",
        "\n",
        "!kaggle competitions submit -c planet-understanding-the-amazon-from-space -f submission.csv -m \"Message\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% 2.26M/2.26M [00:01<00:00, 1.75MB/s]\n",
            "Successfully submitted to Planet: Understanding the Amazon from Space"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}